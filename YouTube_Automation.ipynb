{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFRtr5hZRxYAmvcK57oGkM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SHUBHAMDw/First/blob/master/YouTube_Automation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1B-oO0qdTnC",
        "outputId": "610f31b8-4ed7-4d46-a027-90785ac603de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/740.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.1/740.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m737.3/740.1 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m740.1/740.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Cell 1: Install Dependencies\n",
        "!pip install openai \"elevenlabs>=1.0.0\" requests moviepy -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Create the news source file\n",
        "%%writefile news_sources.csv\n",
        "topic,url,keywords\n",
        "\"AI Chip Race\",\"https://www.reuters.com/technology/nvidia-partners-indias-reliance-tata-ai-infrastructure-2023-09-08/\",\"technology, AI, computer chip\"\n",
        "\"New Space Telescope\",\"https://www.example.com/some-space-article\",\"space, galaxy, stars\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_vnv0WKhDrN",
        "outputId": "1c1422fc-6c31-4d75-b28b-3a4bc1f36c34"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing news_sources.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: The Full Pipeline Code\n",
        "\n",
        "import os\n",
        "import csv\n",
        "import requests\n",
        "from google.colab import userdata  # The Colab way to get secrets\n",
        "from openai import OpenAI\n",
        "from elevenlabs import Voice, VoiceSettings\n",
        "from elevenlabs.client import ElevenLabs\n",
        "from moviepy.editor import *\n",
        "\n",
        "# --- 1. CONFIGURATION & SETUP ---\n",
        "# Load API keys from Colab Secrets\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "ELEVENLABS_API_KEY = userdata.get('ELEVENLABS_API_KEY')\n",
        "PEXELS_API_KEY = userdata.get('PEXELS_API_KEY')\n",
        "\n",
        "# ElevenLabs Voice ID (Replace with your chosen voice ID from the ElevenLabs website)\n",
        "ELEVENLABS_VOICE_ID = \"21m00Tcm4TlvDq8ikWAM\" # Example: Rachel's voice\n",
        "\n",
        "# Initialize API clients\n",
        "openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "elevenlabs_client = ElevenLabs(api_key=ELEVENLABS_API_KEY)\n",
        "\n",
        "# --- 2. PIPELINE FUNCTIONS (Identical to the previous script) ---\n",
        "\n",
        "def get_news_from_source(file_path='news_sources.csv'):\n",
        "    with open(file_path, 'r') as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        return next(reader)\n",
        "\n",
        "def generate_news_script(topic, url):\n",
        "    print(f\"-> Generating script for topic: {topic}\")\n",
        "    prompt = f\"\"\"\n",
        "    You are a professional news anchor. Write a concise and engaging 150-word news script\n",
        "    about the topic \"{topic}\". The information is based on the article at this URL: {url}.\n",
        "    Start with a strong hook and maintain a professional, clear tone.\n",
        "    Do not include any intro or sign-off like \"Hello and welcome\" or \"Thanks for watching\".\n",
        "    Just provide the script body.\n",
        "    \"\"\"\n",
        "    response = openai_client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    script = response.choices[0].message.content.strip()\n",
        "    print(f\"-> Script generated successfully.\")\n",
        "    return script\n",
        "\n",
        "def generate_anchor_audio(script_text, output_path=\"anchor_audio.mp3\"):\n",
        "    print(\"-> Generating anchor audio...\")\n",
        "    audio = elevenlabs_client.generate(\n",
        "        text=script_text,\n",
        "        voice=Voice(voice_id=ELEVENLABS_VOICE_ID),\n",
        "        model=\"eleven_multilingual_v2\"\n",
        "    )\n",
        "    with open(output_path, \"wb\") as f:\n",
        "        f.write(audio)\n",
        "    print(f\"-> Audio saved to {output_path}\")\n",
        "    return output_path\n",
        "\n",
        "def find_and_download_broll(keywords, output_path=\"broll_video.mp4\"):\n",
        "    print(f\"-> Searching for B-roll with keywords: {keywords}\")\n",
        "    headers = {\"Authorization\": PEXELS_API_KEY}\n",
        "    query = keywords.split(',')[0].strip()\n",
        "    url = f\"https://api.pexels.com/videos/search?query={query}&per_page=1&orientation=landscape\"\n",
        "    response = requests.get(url, headers=headers)\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Error: Failed to fetch video from Pexels. Response: {response.text}\")\n",
        "        return None\n",
        "    data = response.json()\n",
        "    if not data.get('videos'):\n",
        "        print(f\"Error: No videos found for '{query}'\")\n",
        "        return None\n",
        "    video_files = data['videos'][0]['video_files']\n",
        "    video_url = next((vid['link'] for vid in video_files if vid.get('quality') == 'hd'), None)\n",
        "    if not video_url:\n",
        "        print(\"Error: No suitable HD video link found.\")\n",
        "        return None\n",
        "    print(f\"-> Downloading B-roll from {video_url}\")\n",
        "    video_response = requests.get(video_url)\n",
        "    with open(output_path, \"wb\") as f:\n",
        "        f.write(video_response.content)\n",
        "    print(f\"-> B-roll saved to {output_path}\")\n",
        "    return output_path\n",
        "\n",
        "def create_final_video(audio_path, video_path, output_path=\"final_video.mp4\"):\n",
        "    print(\"-> Assembling final video...\")\n",
        "    audio_clip = AudioFileClip(audio_path)\n",
        "    video_clip = VideoFileClip(video_path)\n",
        "    video_clip = video_clip.subclip(0, audio_clip.duration).fx(vfx.fadeout, 1)\n",
        "    final_clip = video_clip.set_audio(audio_clip)\n",
        "    final_clip.write_videofile(\n",
        "        output_path,\n",
        "        codec='libx264',\n",
        "        audio_codec='aac',\n",
        "        temp_audiofile='temp-audio.m4a',\n",
        "        remove_temp=True\n",
        "    )\n",
        "    print(f\"-> Final video saved to {output_path}\")\n",
        "\n",
        "# --- 3. MAIN EXECUTION BLOCK ---\n",
        "\n",
        "def main():\n",
        "    print(\"--- Automated Video Pipeline Started ---\")\n",
        "    news_item = get_news_from_source()\n",
        "    script = generate_news_script(news_item['topic'], news_item['url'])\n",
        "    audio_file = generate_anchor_audio(script)\n",
        "    broll_video_file = find_and_download_broll(news_item['keywords'])\n",
        "    if not broll_video_file:\n",
        "        print(\"Halting pipeline: Could not get B-roll footage.\")\n",
        "        return\n",
        "    create_final_video(audio_file, broll_video_file)\n",
        "    print(\"--- Pipeline Complete ---\")\n",
        "    print(\"Find 'final_video.mp4' in the file browser on the left.\")\n",
        "\n",
        "# Run the pipeline!\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "p1ACr9B0hJ9p",
        "outputId": "bc80d26c-59c4-45da-8d86-e146a67d91b8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Automated Video Pipeline Started ---\n",
            "-> Generating script for topic: AI Chip Race\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RateLimitError",
          "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-5-3686749299.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;31m# Run the pipeline!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-5-3686749299.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- Automated Video Pipeline Started ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0mnews_item\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_news_from_source\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mscript\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_news_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnews_item\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'topic'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnews_item\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'url'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0maudio_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_anchor_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscript\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0mbroll_video_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_and_download_broll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnews_item\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keywords'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-5-3686749299.py\u001b[0m in \u001b[0;36mgenerate_news_script\u001b[0;34m(topic, url)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mJust\u001b[0m \u001b[0mprovide\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mscript\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \"\"\"\n\u001b[0;32m---> 41\u001b[0;31m     response = openai_client.chat.completions.create(\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-4o\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/resources/chat/completions/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    923\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m    924\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    926\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1240\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m         )\n\u001b[0;32m-> 1242\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "L_q1QMZrjoD0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "9nykGTnNjuU4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}